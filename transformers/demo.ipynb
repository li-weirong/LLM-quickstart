{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d288c67-f496-47ac-8245-6dd171890fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DASHSCOPE_API_KEY=sk-057d8d26302f4d749a435c8be3458fc7\n"
     ]
    }
   ],
   "source": [
    "%env DASHSCOPE_API_KEY=sk-057d8d26302f4d749a435c8be3458fc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57983246-4104-4d44-8026-46f2502987d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from http import HTTPStatus\n",
    "from dashscope import Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f45f8e62-1e4b-4a5f-a119-68d8fe8e894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='''你是重庆小雨点的一个信贷审核员，你需要根据用户的申请记录打电话与用户沟通确认用户的身份和贷款信息是否。\n",
    "        接下来我们模拟电话沟通，我作为用户会逐一回答你的问题，请你模拟电话接通后开始逐一提问，我们一问一答，直到所有问题都经过确认。\n",
    "        以下是示例：\n",
    "        <|assistant|>：你好，我是重庆小雨点的审核员，请问是{用户名}吗？\n",
    "        <|user|>：是的，有什么事情？\n",
    "        <|assistant|>：我们收到了一笔贷款申请，想和你核实一下。通话有录音。请问你的身份证号后四位是什么？\n",
    "        <|user|>：是{身份证号后四位}。\n",
    "        <|assistant|>：好的，和申请记录一致。请问这次贷款申请是你本人发起的吗？\n",
    "        <|user|>：是的。\n",
    "        <|assistant|>：请问这次贷款申请的用途是什么？\n",
    "        <|user|>：用来做美容\n",
    "        <|assistant|>：请问你是在哪家美容机构进行的申请？\n",
    "        <|user|>：{美容机构名}\n",
    "        <|assistant|>：好的，我这边确认晚了。我将尽快将您的信息提交给相关部门进行进一步处理。请您耐心等待，一般情况下，我们会在尽快的时间内通知您关于贷款批准或者需要提供额外信息的情况。如果您有其他紧急的问题或者需要了解更多信息，请随时告诉我，我将尽力帮助您。再见！\n",
    "        <|user|>：好的，再见'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca0e95fe-81f5-442d-84df-27c1db5635d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {'role': 'system', 'content': '''\n",
    "            以下是用户的申请记录：\n",
    "            申请人：王美丽\n",
    "            申请时间：2023年12月13日\n",
    "            申请原因：光子嫩肤\n",
    "            美容机构：华韩整形重庆分院\n",
    "            身份证号：500101198212156725\n",
    "            '''}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d42c191-7b7d-4a88-8e67-8a4d8302d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_with_stream(prompt, messages):\n",
    "    responses = Generation.call(\n",
    "        Generation.Models.qwen_turbo,\n",
    "        messages=messages,\n",
    "        prompt=prompt,\n",
    "        result_format='message',  # set the result to be \"message\" format.\n",
    "        stream=True,\n",
    "        incremental_output=True  # get streaming output incrementally\n",
    "    )\n",
    "    full_content = ''  # with incrementally we need to merge output.\n",
    "    for response in responses:\n",
    "        if response.status_code == HTTPStatus.OK:\n",
    "            full_content += response.output.choices[0]['message']['content']\n",
    "            print(response)\n",
    "        else:\n",
    "            print('Request id: %s, Status code: %s, error code: %s, error message: %s' % (\n",
    "                response.request_id, response.status_code,\n",
    "                response.code, response.message\n",
    "            ))\n",
    "    print('Full response:\\n' + full_content)\n",
    "    return full_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c57dced-5d49-4cb0-807a-ac8fa1044f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status_code\": 200, \"request_id\": \"1a7d5c64-4a3f-9b5c-b3a5-938df3770c05\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"null\", \"message\": {\"role\": \"assistant\", \"content\": \"<|assistant\"}}]}, \"usage\": {\"input_tokens\": 402, \"output_tokens\": 3, \"total_tokens\": 405}}\n",
      "{\"status_code\": 200, \"request_id\": \"1a7d5c64-4a3f-9b5c-b3a5-938df3770c05\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"null\", \"message\": {\"role\": \"assistant\", \"content\": \"|>：您好，我是重庆小雨点的\"}}]}, \"usage\": {\"input_tokens\": 402, \"output_tokens\": 14, \"total_tokens\": 416}}\n",
      "{\"status_code\": 200, \"request_id\": \"1a7d5c64-4a3f-9b5c-b3a5-938df3770c05\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"null\", \"message\": {\"role\": \"assistant\", \"content\": \"信贷审核员，请问您是王美丽女士\"}}]}, \"usage\": {\"input_tokens\": 402, \"output_tokens\": 24, \"total_tokens\": 426}}\n",
      "{\"status_code\": 200, \"request_id\": \"1a7d5c64-4a3f-9b5c-b3a5-938df3770c05\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"null\", \"message\": {\"role\": \"assistant\", \"content\": \"吗？（注意核对姓名、性别等\"}}]}, \"usage\": {\"input_tokens\": 402, \"output_tokens\": 34, \"total_tokens\": 436}}\n",
      "{\"status_code\": 200, \"request_id\": \"1a7d5c64-4a3f-9b5c-b3a5-938df3770c05\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"null\", \"message\": {\"role\": \"assistant\", \"content\": \"基本信息）\"}}]}, \"usage\": {\"input_tokens\": 402, \"output_tokens\": 36, \"total_tokens\": 438}}\n",
      "{\"status_code\": 200, \"request_id\": \"1a7d5c64-4a3f-9b5c-b3a5-938df3770c05\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"stop\", \"message\": {\"role\": \"assistant\", \"content\": \"\"}}]}, \"usage\": {\"input_tokens\": 402, \"output_tokens\": 36, \"total_tokens\": 438}}\n",
      "Full response:\n",
      "<|assistant|>：您好，我是重庆小雨点的信贷审核员，请问您是王美丽女士吗？（注意核对姓名、性别等基本信息）\n"
     ]
    }
   ],
   "source": [
    "full_content = call_with_stream(prompt,messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b95ae23-6b0f-4356-90bd-a65b218fbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_speech_for_sentence(history, chatbot_role, sentence, return_as_byte=False):\n",
    "    language = \"autodetect\"\n",
    "\n",
    "    wav_bytestream = b\"\"\n",
    "    \n",
    "    if len(sentence)==0:\n",
    "        print(\"EMPTY SENTENCE\")\n",
    "        return \n",
    "    \n",
    "    # Sometimes prompt </s> coming on output remove it\n",
    "    # Some post process for speech only\n",
    "    sentence = sentence.replace(\"</s>\", \"\")\n",
    "    # remove code from speech\n",
    "    sentence = re.sub(\"```.*```\", \"\", sentence, flags=re.DOTALL)\n",
    "    sentence = re.sub(\"`.*`\", \"\", sentence, flags=re.DOTALL)\n",
    "    \n",
    "    sentence = re.sub(\"\\(.*\\)\", \"\", sentence, flags=re.DOTALL)\n",
    "    \n",
    "    sentence = sentence.replace(\"```\", \"\")\n",
    "    sentence = sentence.replace(\"...\", \" \")\n",
    "    sentence = sentence.replace(\"(\", \" \")\n",
    "    sentence = sentence.replace(\")\", \" \")\n",
    "    sentence = sentence.replace(\"<|assistant|>\",\"\")\n",
    "\n",
    "    if len(sentence)==0:\n",
    "        print(\"EMPTY SENTENCE after processing\")\n",
    "        return \n",
    "        \n",
    "    # A fast fix for last chacter, may produce weird sounds if it is with text\n",
    "    #if (sentence[-1] in [\"!\", \"?\", \".\", \",\"]) or (sentence[-2] in [\"!\", \"?\", \".\", \",\"]):\n",
    "    #    # just add a space\n",
    "    #    sentence = sentence[:-1] + \" \" + sentence[-1]\n",
    "        \n",
    "    # regex does the job well\n",
    "    sentence= re.sub(\"([^\\x00-\\x7F]|\\w)(\\.|\\。|\\?|\\!)\",r\"\\1 \\2\\2\",sentence)\n",
    "    \n",
    "    print(\"Sentence for speech:\", sentence)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        SENTENCE_SPLIT_LENGTH=350\n",
    "        if len(sentence)<SENTENCE_SPLIT_LENGTH:\n",
    "            # no problem continue on\n",
    "            sentence_list = [sentence]\n",
    "        else:\n",
    "            # Until now nltk likely split sentences properly but we need additional \n",
    "            # check for longer sentence and split at last possible position\n",
    "            # Do whatever necessary, first break at hypens then spaces and then even split very long words\n",
    "            sentence_list=textwrap.wrap(sentence,SENTENCE_SPLIT_LENGTH)\n",
    "            print(\"SPLITTED LONG SENTENCE:\",sentence_list)\n",
    "        \n",
    "        for sentence in sentence_list:\n",
    "            \n",
    "            if any(c.isalnum() for c in sentence):\n",
    "                if language==\"autodetect\":\n",
    "                    #on first call autodetect, nexts sentence calls will use same language\n",
    "                    language = detect_language(sentence) \n",
    "            \n",
    "                #exists at least 1 alphanumeric (utf-8) \n",
    "                audio_stream = get_voice_streaming(\n",
    "                        sentence, language, latent_map[chatbot_role]\n",
    "                    )\n",
    "            else:\n",
    "                # likely got a ' or \" or some other text without alphanumeric in it\n",
    "                audio_stream = None \n",
    "                \n",
    "            # XTTS is actually using streaming response but we are playing audio by sentence\n",
    "            # If you want direct XTTS voice streaming (send each chunk to voice ) you may set DIRECT_STREAM=1 environment variable\n",
    "            if audio_stream is not None:\n",
    "                frame_length = 0\n",
    "                for chunk in audio_stream:\n",
    "                    try:\n",
    "                        wav_bytestream += chunk\n",
    "                        frame_length += len(chunk)\n",
    "                    except:\n",
    "                        # hack to continue on playing. sometimes last chunk is empty , will be fixed on next TTS\n",
    "                        continue\n",
    "\n",
    "            # Filter output for better voice\n",
    "            filter_output=False \n",
    "            if filter_output:\n",
    "                data_s16 = np.frombuffer(wav_bytestream, dtype=np.int16, count=len(wav_bytestream)//2, offset=0)\n",
    "                float_data = data_s16 * 0.5**15\n",
    "                reduced_noise = nr.reduce_noise(y=float_data, sr=24000,prop_decrease =0.8,n_fft=1024)\n",
    "                wav_bytestream = (reduced_noise * 32767).astype(np.int16)\n",
    "                wav_bytestream = wav_bytestream.tobytes()\n",
    "                    \n",
    "            if audio_stream is not None:\n",
    "                if not return_as_byte:\n",
    "                    audio_unique_filename = \"/tmp/\"+ str(uuid.uuid4())+\".wav\"\n",
    "                    with wave.open(audio_unique_filename, \"w\") as f:\n",
    "                        f.setnchannels(1)\n",
    "                        # 2 bytes per sample.\n",
    "                        f.setsampwidth(2)\n",
    "                        f.setframerate(24000)\n",
    "                        f.writeframes(wav_bytestream)\n",
    "                           \n",
    "                    return (history , gr.Audio.update(value=audio_unique_filename, autoplay=True))\n",
    "                else:\n",
    "                    return (history , gr.Audio.update(value=wav_bytestream, autoplay=True))\n",
    "    except RuntimeError as e:\n",
    "        if \"device-side assert\" in str(e):\n",
    "            # cannot do anything on cuda device side error, need tor estart\n",
    "            print(\n",
    "                f\"Exit due to: Unrecoverable exception caused by prompt:{sentence}\",\n",
    "                flush=True,\n",
    "            )\n",
    "            gr.Warning(\"Unhandled Exception encounter, please retry in a minute\")\n",
    "            print(\"Cuda device-assert Runtime encountered need restart\")\n",
    "\n",
    "            # HF Space specific.. This error is unrecoverable need to restart space\n",
    "            api.restart_space(repo_id=repo_id)\n",
    "        else:\n",
    "            print(\"RuntimeError: non device-side assert error:\", str(e))\n",
    "            raise e\n",
    "\n",
    "    print(\"All speech ended\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5c8da-4d8e-44e7-b1d5-b426144df162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
